{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Import necessary libraries"
      ],
      "metadata": {
        "id": "Ikscy8dpd0hC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_NFDeJ59dyk4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab0826b9-2d2d-47df-b87e-4db5a9ab81dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processor\t: 0\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 85\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "stepping\t: 3\n",
            "microcode\t: 0xffffffff\n",
            "cpu MHz\t\t: 2000.148\n",
            "cache size\t: 39424 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 2\n",
            "core id\t\t: 0\n",
            "cpu cores\t: 1\n",
            "apicid\t\t: 0\n",
            "initial apicid\t: 0\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 13\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves arat md_clear arch_capabilities\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa mmio_stale_data retbleed\n",
            "bogomips\t: 4000.29\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n",
            "processor\t: 1\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 85\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "stepping\t: 3\n",
            "microcode\t: 0xffffffff\n",
            "cpu MHz\t\t: 2000.148\n",
            "cache size\t: 39424 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 2\n",
            "core id\t\t: 0\n",
            "cpu cores\t: 1\n",
            "apicid\t\t: 1\n",
            "initial apicid\t: 1\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 13\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves arat md_clear arch_capabilities\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa mmio_stale_data retbleed\n",
            "bogomips\t: 4000.29\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n",
            "Sun Mar 17 10:14:15 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n",
            "2.15.0\n"
          ]
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "\n",
        "!cat /proc/cpuinfo # gives details of CPU\n",
        "\n",
        "!nvidia-smi # gives details of GPU\n",
        "\n",
        "# !pip uninstall tensorflow  #just incase you want to change version\n",
        "# !pip install tensorflow==2.X.0\n",
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "\n",
        "# Commonly used modules\n",
        "import numpy as np\n",
        "import os, datetime\n",
        "import sys\n",
        "\n",
        "# Images, plots, display, and visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "import IPython\n",
        "from six.moves import urllib\n",
        "\n",
        "print(tf.__version__)\n",
        "\n",
        "\n",
        "from matplotlib.pyplot import imshow\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Load CIFAR100 dataset"
      ],
      "metadata": {
        "id": "O-Mg37THd90f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import cifar100\n",
        "(x_train, y_train), (x_test, y_test)  = cifar100.load_data()\n",
        "\n",
        "# return the modified images\n",
        "print(\"Train Images shape: \",x_train.shape)\n",
        "print(\"Test Images shape: \",x_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "-M1xncG-d9Xm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f393f0b-6b6b-4f1a-97a1-3dfebba7f882"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169001437/169001437 [==============================] - 6s 0us/step\n",
            "Train Images shape:  (50000, 32, 32, 3)\n",
            "Test Images shape:  (10000, 32, 32, 3)\n",
            "(50000, 1)\n",
            "(10000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Preprocess Image Data"
      ],
      "metadata": {
        "id": "Vn5_eVJFeFkN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_images(X, Y): # should work for both a single image and multiple images\n",
        "    X_p = keras.applications.densenet.preprocess_input(X)\n",
        "    Y_p = keras.utils.to_categorical(Y, 100)\n",
        "    return X_p, Y_p\n",
        "\n",
        "# preprocess the train images\n",
        "x_train, y_train = preprocess_images(x_train, y_train)\n",
        "\n",
        "# preprocess the test images\n",
        "x_test, y_test = preprocess_images(x_test, y_test)"
      ],
      "metadata": {
        "id": "LWpnnqINeI7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Baseline Model = VGG16\n",
        "Images need to be resized to make the best use of the base model"
      ],
      "metadata": {
        "id": "_lQcRi4seOR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "\n",
        "# input tensor\n",
        "inputs = keras.Input(shape=(32, 32, 3))\n",
        "\n",
        "# upscale layer\n",
        "upscale = keras.layers.Lambda(lambda x: tf.image.resize_with_pad(x,\n",
        "            160,\n",
        "            160,\n",
        "            method=tf.image.ResizeMethod.BILINEAR))(inputs)\n",
        "\n",
        "base_model = VGG16(weights='imagenet',\n",
        "                   include_top=False,\n",
        "                   input_tensor=upscale,\n",
        "                   input_shape=(160,160,3),\n",
        "                   pooling='max')\n",
        "\n",
        "base_model.summary()"
      ],
      "metadata": {
        "id": "VRK2XTuXemdG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9a75b7a-2250-4f12-efe2-f1a678574e84"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " lambda_1 (Lambda)           (None, 160, 160, 3)       0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 160, 160, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 160, 160, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 80, 80, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 80, 80, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 80, 80, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 40, 40, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 40, 40, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 40, 40, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 40, 40, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 20, 20, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 20, 20, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 20, 20, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 20, 20, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 10, 10, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 10, 10, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 10, 10, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 10, 10, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 5, 5, 512)         0         \n",
            "                                                                 \n",
            " global_max_pooling2d_2 (Gl  (None, 512)               0         \n",
            " obalMaxPooling2D)                                               \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14714688 (56.13 MB)\n",
            "Trainable params: 14714688 (56.13 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## The head eg. fully connected network must be set up specific to this dataset\n",
        "out = base_model.output\n",
        "out = keras.layers.Flatten()(out)\n",
        "out = keras.layers.BatchNormalization()(out)\n",
        "out = keras.layers.Dense(256, activation='relu')(out)\n",
        "out = keras.layers.Dropout(0.3)(out)\n",
        "out = keras.layers.BatchNormalization()(out)\n",
        "out = keras.layers.Dense(128, activation='relu')(out)\n",
        "out = keras.layers.Dropout(0.3)(out)\n",
        "out = keras.layers.BatchNormalization()(out)\n",
        "out = keras.layers.Dense(64, activation='relu')(out)\n",
        "out = keras.layers.Dropout(0.3)(out)\n",
        "out = keras.layers.Dense(100, activation='softmax')(out) #key change is that there are 100 output nodes for the 100 classes"
      ],
      "metadata": {
        "id": "vOynT577gH1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analysing Baseline Model"
      ],
      "metadata": {
        "id": "x15YdKCiggeH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CALLBACKS = []\n",
        "MODEL_PATH = 'cifar100.h5'\n",
        "\n",
        "# callbacks\n",
        "CALLBACKS.append(keras.callbacks.ModelCheckpoint(filepath=MODEL_PATH,\n",
        "                                              monitor='val_acc',\n",
        "                                              save_best_only=True))\n",
        "\n",
        "CALLBACKS.append(keras.callbacks.EarlyStopping(monitor='val_acc',\n",
        "                                            verbose=1,\n",
        "                                            patience=5))\n",
        "\n",
        "CALLBACKS.append(keras.callbacks.TensorBoard(log_dir='logs'))\n",
        "\n",
        "model = keras.models.Model(inputs=inputs, outputs=out)\n",
        "\n",
        "# compile the model to use categorical cross-entropy loss function and adadelta optimizer\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=keras.optimizers.Adam(learning_rate = 0.001),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x=x_train, y=y_train,\n",
        "                    batch_size=128,\n",
        "                    epochs=15,\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    callbacks=CALLBACKS)"
      ],
      "metadata": {
        "id": "TW4PCLCtglPm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86d5057e-3f59-4bf7-e917-211ccd40add0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "391/391 [==============================] - ETA: 0s - loss: 4.4795 - accuracy: 0.0295"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r391/391 [==============================] - 415s 948ms/step - loss: 4.4795 - accuracy: 0.0295 - val_loss: 4.7499 - val_accuracy: 0.0192\n",
            "Epoch 2/15\n",
            "391/391 [==============================] - ETA: 0s - loss: 4.1601 - accuracy: 0.0500"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r391/391 [==============================] - 327s 837ms/step - loss: 4.1601 - accuracy: 0.0500 - val_loss: 16.4471 - val_accuracy: 0.0265\n",
            "Epoch 3/15\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.9997 - accuracy: 0.0643"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r391/391 [==============================] - 331s 846ms/step - loss: 3.9997 - accuracy: 0.0643 - val_loss: 4.1698 - val_accuracy: 0.0583\n",
            "Epoch 4/15\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.8358 - accuracy: 0.0885"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r391/391 [==============================] - 330s 845ms/step - loss: 3.8358 - accuracy: 0.0885 - val_loss: 3.6894 - val_accuracy: 0.1177\n",
            "Epoch 5/15\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.6919 - accuracy: 0.1119"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r391/391 [==============================] - 327s 838ms/step - loss: 3.6919 - accuracy: 0.1119 - val_loss: 256.2166 - val_accuracy: 0.0872\n",
            "Epoch 6/15\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.5685 - accuracy: 0.1310"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r391/391 [==============================] - 329s 842ms/step - loss: 3.5685 - accuracy: 0.1310 - val_loss: 66.8859 - val_accuracy: 0.1467\n",
            "Epoch 7/15\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.4434 - accuracy: 0.1506"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r391/391 [==============================] - 329s 842ms/step - loss: 3.4434 - accuracy: 0.1506 - val_loss: 3.6547 - val_accuracy: 0.1413\n",
            "Epoch 8/15\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.3109 - accuracy: 0.1750"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r391/391 [==============================] - 329s 841ms/step - loss: 3.3109 - accuracy: 0.1750 - val_loss: 3.6470 - val_accuracy: 0.1527\n",
            "Epoch 9/15\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.1936 - accuracy: 0.1956"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r391/391 [==============================] - 327s 837ms/step - loss: 3.1936 - accuracy: 0.1956 - val_loss: 3.4608 - val_accuracy: 0.1771\n",
            "Epoch 10/15\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.0866 - accuracy: 0.2166"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r391/391 [==============================] - 329s 841ms/step - loss: 3.0866 - accuracy: 0.2166 - val_loss: 1375.0081 - val_accuracy: 0.2398\n",
            "Epoch 11/15\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.9852 - accuracy: 0.2367"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r391/391 [==============================] - 329s 841ms/step - loss: 2.9852 - accuracy: 0.2367 - val_loss: 424.6422 - val_accuracy: 0.2612\n",
            "Epoch 12/15\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.8937 - accuracy: 0.2527"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r391/391 [==============================] - 329s 841ms/step - loss: 2.8937 - accuracy: 0.2527 - val_loss: 2.9625 - val_accuracy: 0.2678\n",
            "Epoch 13/15\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.8243 - accuracy: 0.2663"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r391/391 [==============================] - 328s 840ms/step - loss: 2.8243 - accuracy: 0.2663 - val_loss: 2207.4692 - val_accuracy: 0.2675\n",
            "Epoch 14/15\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.7419 - accuracy: 0.2854"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r391/391 [==============================] - 326s 835ms/step - loss: 2.7419 - accuracy: 0.2854 - val_loss: 2.8467 - val_accuracy: 0.2954\n",
            "Epoch 15/15\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.6634 - accuracy: 0.2991"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r391/391 [==============================] - 328s 839ms/step - loss: 2.6634 - accuracy: 0.2991 - val_loss: 2.6371 - val_accuracy: 0.3344\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(16,4))\n",
        "ax = fig.add_subplot(121)\n",
        "ax.plot(history.history[\"val_loss\"])\n",
        "ax.set_title(\"validation loss\")\n",
        "ax.set_xlabel(\"epochs\")\n",
        "\n",
        "ax2 = fig.add_subplot(122)\n",
        "ax2.plot(history.history[\"val_accuracy\"])\n",
        "ax2.set_title(\"validation accuracy\")\n",
        "ax2.set_xlabel(\"epochs\")\n",
        "ax2.set_ylim(0, 1)\n",
        "\n",
        "plt.show()\n",
        "plt.savefig('Baseline_model_accuracy.png')"
      ],
      "metadata": {
        "id": "CfYXtTQ8g3yy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "d5c96bdb-13b7-4a7f-b27f-24bc29db32b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analysing Baseline Model with frozen backbone"
      ],
      "metadata": {
        "id": "5Vy8gwmYihss"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://keras.io/guides/transfer_learning/"
      ],
      "metadata": {
        "id": "YeishT6j6vkv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# input tensor\n",
        "inputs = keras.Input(shape=(32, 32, 3))\n",
        "\n",
        "# upscale layer\n",
        "upscale = keras.layers.Lambda(lambda x: tf.image.resize_with_pad(x,\n",
        "            160,\n",
        "            160,\n",
        "            method=tf.image.ResizeMethod.BILINEAR))(inputs)\n",
        "\n",
        "frozen_model = VGG16(weights='imagenet',\n",
        "                   include_top=False,\n",
        "                   input_tensor=upscale,\n",
        "                   input_shape=(160,160,3),\n",
        "                   pooling='max')\n",
        "# Might need to remove the pooling max to then compare against"
      ],
      "metadata": {
        "id": "pxcvpOXuhG8A"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frozen_model.trainable = False # freeze backbone"
      ],
      "metadata": {
        "id": "OQEM2yGaj8u9"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We make sure that the base_model is running in inference mode here,\n",
        "# by passing `training=False`\n",
        "x = frozen_model(inputs, training=False)\n",
        "# Convert features of shape `base_model.output_shape[1:]` to vectors\n",
        "# x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = frozen_model.output\n",
        "x = keras.layers.Flatten()(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.Dense(256, activation='relu')(x)\n",
        "x = keras.layers.Dropout(0.3)(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.Dense(128, activation='relu')(x)\n",
        "x = keras.layers.Dropout(0.3)(x)\n",
        "# maybe change this to see if reducing no. of connected layers speeds up the training adn if the accuracy increases\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.Dense(64, activation='relu')(x)\n",
        "x = keras.layers.Dropout(0.3)(x)\n",
        "# A Dense classifier with a 100 classes\n",
        "outputs = keras.layers.Dense(100, activation='softmax')(x)"
      ],
      "metadata": {
        "id": "3W4cp2LIj8yW"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CALLBACKS = []\n",
        "MODEL_PATH = 'cifar100.h5'\n",
        "\n",
        "# callbacks\n",
        "CALLBACKS.append(keras.callbacks.ModelCheckpoint(filepath=MODEL_PATH,\n",
        "                                              monitor='val_acc',\n",
        "                                              save_best_only=True))\n",
        "\n",
        "CALLBACKS.append(keras.callbacks.EarlyStopping(monitor='val_acc',\n",
        "                                            verbose=1,\n",
        "                                            patience=5))\n",
        "\n",
        "CALLBACKS.append(keras.callbacks.TensorBoard(log_dir='logs'))\n",
        "\n",
        "model = keras.models.Model(inputs, outputs)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=keras.optimizers.Adam(learning_rate = 0.001),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x=x_train, y=y_train,\n",
        "                    batch_size=128,\n",
        "                    epochs=15,\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    callbacks=CALLBACKS)"
      ],
      "metadata": {
        "id": "b_N_cJmTnZwq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e70126c6-7a56-431f-8e05-ecc1f6a91ca4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.7716 - accuracy: 0.1270"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r391/391 [==============================] - 117s 292ms/step - loss: 3.7716 - accuracy: 0.1270 - val_loss: 2.5897 - val_accuracy: 0.3446\n",
            "Epoch 2/15\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.8292 - accuracy: 0.2640"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r391/391 [==============================] - 118s 301ms/step - loss: 2.8292 - accuracy: 0.2640 - val_loss: 2.2105 - val_accuracy: 0.4099\n",
            "Epoch 3/15\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.5540 - accuracy: 0.3190"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r391/391 [==============================] - 121s 310ms/step - loss: 2.5540 - accuracy: 0.3190 - val_loss: 2.0689 - val_accuracy: 0.4443\n",
            "Epoch 4/15\n",
            "323/391 [=======================>......] - ETA: 17s - loss: 2.4150 - accuracy: 0.3522"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(16,4))\n",
        "ax = fig.add_subplot(121)\n",
        "ax.plot(history.history[\"val_loss\"])\n",
        "ax.set_title(\"validation loss\")\n",
        "ax.set_xlabel(\"epochs\")\n",
        "\n",
        "ax2 = fig.add_subplot(122)\n",
        "ax2.plot(history.history[\"val_accuracy\"])\n",
        "ax2.set_title(\"validation accuracy\")\n",
        "ax2.set_xlabel(\"epochs\")\n",
        "ax2.set_ylim(0, 1)\n",
        "\n",
        "plt.show()\n",
        "plt.savefig('Frozen_Baseline_model_accuracy.png')"
      ],
      "metadata": {
        "id": "4VzQyXYwoOHH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "75339f57-7087-42b3-bf7e-f5bce945a290"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'plt' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-efa3ec7e21fd>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m121\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"validation loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epochs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finetuning the model"
      ],
      "metadata": {
        "id": "qguzm-N57Lax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Unfreeze the base model\n",
        "base_model.trainable = True\n",
        "\n",
        "# It's important to recompile your model after you make any changes\n",
        "# to the `trainable` attribute of any inner layer, so that your changes\n",
        "# are take into account\n",
        "model.compile(optimizer=keras.optimizers.Adam(1e-5),  # Very low learning rate\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train end-to-end. Be careful to stop before you overfit!\n",
        "history = model.fit(x=x_train, y=y_train, epochs=10, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "id": "hfgiF0zt7K_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P2Elb2YR7hJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Test Model 1 = DenseNet121\n",
        "Selected due to lower size and parameters than baseline model but higher top1 and top5 accuracy likely due to the depth of the Model."
      ],
      "metadata": {
        "id": "mJBjlBoKfJY6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_model1 = keras.applications.DenseNet121(include_top=False,\n",
        "                                        weights='imagenet',\n",
        "                                        input_tensor=upscale,\n",
        "                                        input_shape=(160,160,3),\n",
        "                                        pooling='max')\n",
        "\n",
        "test_model1.summary()"
      ],
      "metadata": {
        "id": "j_BtIpGMgBG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = test_model1.output\n",
        "out = keras.layers.Flatten()(out)\n",
        "out = keras.layers.BatchNormalization()(out)\n",
        "out = keras.layers.Dense(256, activation='relu')(out)\n",
        "out = keras.layers.Dropout(0.3)(out)\n",
        "out = keras.layers.BatchNormalization()(out)\n",
        "out = keras.layers.Dense(128, activation='relu')(out)\n",
        "out = keras.layers.Dropout(0.3)(out)\n",
        "out = keras.layers.BatchNormalization()(out)\n",
        "out = keras.layers.Dense(64, activation='relu')(out)\n",
        "out = keras.layers.Dropout(0.3)(out)\n",
        "out = keras.layers.Dense(100, activation='softmax')(out) #key change is that there are 100 output nodes for the 100 classes"
      ],
      "metadata": {
        "id": "cN_115pElidE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CALLBACKS = []\n",
        "MODEL_PATH = 'cifar100.h5'\n",
        "\n",
        "# callbacks\n",
        "CALLBACKS.append(keras.callbacks.ModelCheckpoint(filepath=MODEL_PATH,\n",
        "                                              monitor='val_acc',\n",
        "                                              save_best_only=True))\n",
        "\n",
        "CALLBACKS.append(keras.callbacks.EarlyStopping(monitor='val_acc',\n",
        "                                            verbose=1,\n",
        "                                            patience=5))\n",
        "\n",
        "CALLBACKS.append(keras.callbacks.TensorBoard(log_dir='logs'))\n",
        "\n",
        "model = keras.models.Model(inputs, outputs)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=keras.optimizers.Adam(learning_rate = 0.001),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x=x_train, y=y_train,\n",
        "                    batch_size=128,\n",
        "                    epochs=15,\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    callbacks=CALLBACKS)"
      ],
      "metadata": {
        "id": "oOMJKZFdmf-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(16,4))\n",
        "ax = fig.add_subplot(121)\n",
        "ax.plot(history.history[\"val_loss\"])\n",
        "ax.plot(history2.history[\"val_loss\"])\n",
        "ax.set_title(\"validation loss\")\n",
        "ax.set_xlabel(\"epochs\")\n",
        "\n",
        "ax2 = fig.add_subplot(122)\n",
        "ax2.plot(history.history[\"val_accuracy\"])\n",
        "ax2.plot(history2.history[\"val_accuracy\"])\n",
        "ax2.set_title(\"validation accuracy\")\n",
        "ax2.set_xlabel(\"epochs\")\n",
        "ax2.set_ylim(0, 1)\n",
        "\n",
        "plt.show()\n",
        "plt.savefig('Test1_model_accuracy.png')"
      ],
      "metadata": {
        "id": "q--Vj_w8mnZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Test Model 2 = Xception"
      ],
      "metadata": {
        "id": "qPbr2339hvx-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_model2 = keras.applications.Xception(include_top=False,\n",
        "                                          weights='imagenet',\n",
        "                                          input_tensor=upscale,\n",
        "                                          input_shape=(160,160,3),\n",
        "                                          pooling='max')\n",
        "\n",
        "test_model2.summary()"
      ],
      "metadata": {
        "id": "Gs8SalVkh743"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = test_model2.output\n",
        "out = keras.layers.Flatten()(out)\n",
        "out = keras.layers.BatchNormalization()(out)\n",
        "out = keras.layers.Dense(256, activation='relu')(out)\n",
        "out = keras.layers.Dropout(0.3)(out)\n",
        "out = keras.layers.BatchNormalization()(out)\n",
        "out = keras.layers.Dense(128, activation='relu')(out)\n",
        "out = keras.layers.Dropout(0.3)(out)\n",
        "out = keras.layers.BatchNormalization()(out)\n",
        "out = keras.layers.Dense(64, activation='relu')(out)\n",
        "out = keras.layers.Dropout(0.3)(out)\n",
        "out = keras.layers.Dense(100, activation='softmax')(out) #key change is that there are 100 output nodes for the 100 classes"
      ],
      "metadata": {
        "id": "_Kibr2f-lkjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CALLBACKS = []\n",
        "MODEL_PATH = 'cifar100.h5'\n",
        "\n",
        "# callbacks\n",
        "CALLBACKS.append(keras.callbacks.ModelCheckpoint(filepath=MODEL_PATH,\n",
        "                                              monitor='val_acc',\n",
        "                                              save_best_only=True))\n",
        "\n",
        "CALLBACKS.append(keras.callbacks.EarlyStopping(monitor='val_acc',\n",
        "                                            verbose=1,\n",
        "                                            patience=5))\n",
        "\n",
        "CALLBACKS.append(keras.callbacks.TensorBoard(log_dir='logs'))\n",
        "\n",
        "model = keras.models.Model(inputs, outputs)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=keras.optimizers.Adam(learning_rate = 0.001),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x=x_train, y=y_train,\n",
        "                    batch_size=128,\n",
        "                    epochs=15,\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    callbacks=CALLBACKS)"
      ],
      "metadata": {
        "id": "CQ3zoIEimuSz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(16,4))\n",
        "ax = fig.add_subplot(121)\n",
        "ax.plot(history.history[\"val_loss\"])\n",
        "ax.plot(history2.history[\"val_loss\"])\n",
        "ax.set_title(\"validation loss\")\n",
        "ax.set_xlabel(\"epochs\")\n",
        "\n",
        "ax2 = fig.add_subplot(122)\n",
        "ax2.plot(history.history[\"val_accuracy\"])\n",
        "ax2.plot(history2.history[\"val_accuracy\"])\n",
        "ax2.set_title(\"validation accuracy\")\n",
        "ax2.set_xlabel(\"epochs\")\n",
        "ax2.set_ylim(0, 1)\n",
        "\n",
        "plt.show()\n",
        "plt.savefig('Test2_model_accuracy.png')"
      ],
      "metadata": {
        "id": "dt83gLk1mvJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Model 3 = ResNet101"
      ],
      "metadata": {
        "id": "7a-uwLWvh1wC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_model3 = keras.applications.ResNet101(include_top=False,\n",
        "                                          weights='imagenet',\n",
        "                                          input_tensor=upscale,\n",
        "                                          input_shape=(160,160,3),\n",
        "                                          pooling='max')\n",
        "\n",
        "test_model3.summary()"
      ],
      "metadata": {
        "id": "BZVhB7fBiNDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = test_model3.output\n",
        "out = keras.layers.Flatten()(out)\n",
        "out = keras.layers.BatchNormalization()(out)\n",
        "out = keras.layers.Dense(256, activation='relu')(out)\n",
        "out = keras.layers.Dropout(0.3)(out)\n",
        "out = keras.layers.BatchNormalization()(out)\n",
        "out = keras.layers.Dense(128, activation='relu')(out)\n",
        "out = keras.layers.Dropout(0.3)(out)\n",
        "out = keras.layers.BatchNormalization()(out)\n",
        "out = keras.layers.Dense(64, activation='relu')(out)\n",
        "out = keras.layers.Dropout(0.3)(out)\n",
        "out = keras.layers.Dense(100, activation='softmax')(out) #key change is that there are 100 output nodes for the 100 classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "M3A2CvY1llh9",
        "outputId": "a3842ede-a1cc-46d5-b6f8-99b858ba5b49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'base_model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-6e6f8892853e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'base_model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CALLBACKS = []\n",
        "MODEL_PATH = 'cifar100.h5'\n",
        "\n",
        "# callbacks\n",
        "CALLBACKS.append(keras.callbacks.ModelCheckpoint(filepath=MODEL_PATH,\n",
        "                                              monitor='val_acc',\n",
        "                                              save_best_only=True))\n",
        "\n",
        "CALLBACKS.append(keras.callbacks.EarlyStopping(monitor='val_acc',\n",
        "                                            verbose=1,\n",
        "                                            patience=5))\n",
        "\n",
        "CALLBACKS.append(keras.callbacks.TensorBoard(log_dir='logs'))\n",
        "\n",
        "model = keras.models.Model(inputs, outputs)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=keras.optimizers.Adam(learning_rate = 0.001),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x=x_train, y=y_train,\n",
        "                    batch_size=128,\n",
        "                    epochs=15,\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    callbacks=CALLBACKS)"
      ],
      "metadata": {
        "id": "GPuY5-Fymy1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(16,4))\n",
        "ax = fig.add_subplot(121)\n",
        "ax.plot(history.history[\"val_loss\"])\n",
        "ax.plot(history2.history[\"val_loss\"])\n",
        "ax.set_title(\"validation loss\")\n",
        "ax.set_xlabel(\"epochs\")\n",
        "\n",
        "ax2 = fig.add_subplot(122)\n",
        "ax2.plot(history.history[\"val_accuracy\"])\n",
        "ax2.plot(history2.history[\"val_accuracy\"])\n",
        "ax2.set_title(\"validation accuracy\")\n",
        "ax2.set_xlabel(\"epochs\")\n",
        "ax2.set_ylim(0, 1)\n",
        "\n",
        "plt.show()\n",
        "plt.savefig('Test3_model_accuracy.png')"
      ],
      "metadata": {
        "id": "gHFHevotm1VR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Test Model 4 = ResNet152"
      ],
      "metadata": {
        "id": "QFPE58j-h5Xf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_model4 = keras.applications.ResNet152(include_top=False,\n",
        "                                          weights='imagenet',\n",
        "                                          input_tensor=upscale,\n",
        "                                          input_shape=(160,160,3),\n",
        "                                          pooling='max')\n",
        "\n",
        "test_model4.summary()"
      ],
      "metadata": {
        "id": "YjRKHioooVIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = test_model4.output\n",
        "out = keras.layers.Flatten()(out)\n",
        "out = keras.layers.BatchNormalization()(out)\n",
        "out = keras.layers.Dense(256, activation='relu')(out)\n",
        "out = keras.layers.Dropout(0.3)(out)\n",
        "out = keras.layers.BatchNormalization()(out)\n",
        "out = keras.layers.Dense(128, activation='relu')(out)\n",
        "out = keras.layers.Dropout(0.3)(out)\n",
        "out = keras.layers.BatchNormalization()(out)\n",
        "out = keras.layers.Dense(64, activation='relu')(out)\n",
        "out = keras.layers.Dropout(0.3)(out)\n",
        "out = keras.layers.Dense(100, activation='softmax')(out) #key change is that there are 100 output nodes for the 100 classes"
      ],
      "metadata": {
        "id": "5oqS85sElona"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CALLBACKS = []\n",
        "MODEL_PATH = 'cifar100.h5'\n",
        "\n",
        "# callbacks\n",
        "CALLBACKS.append(keras.callbacks.ModelCheckpoint(filepath=MODEL_PATH,\n",
        "                                              monitor='val_acc',\n",
        "                                              save_best_only=True))\n",
        "\n",
        "CALLBACKS.append(keras.callbacks.EarlyStopping(monitor='val_acc',\n",
        "                                            verbose=1,\n",
        "                                            patience=5))\n",
        "\n",
        "CALLBACKS.append(keras.callbacks.TensorBoard(log_dir='logs'))\n",
        "\n",
        "model = keras.models.Model(inputs, outputs)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=keras.optimizers.Adam(learning_rate = 0.001),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x=x_train, y=y_train,\n",
        "                    batch_size=128,\n",
        "                    epochs=15,\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    callbacks=CALLBACKS)"
      ],
      "metadata": {
        "id": "VWu7kPnNm5tA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(16,4))\n",
        "ax = fig.add_subplot(121)\n",
        "ax.plot(history.history[\"val_loss\"])\n",
        "ax.plot(history2.history[\"val_loss\"])\n",
        "ax.set_title(\"validation loss\")\n",
        "ax.set_xlabel(\"epochs\")\n",
        "\n",
        "ax2 = fig.add_subplot(122)\n",
        "ax2.plot(history.history[\"val_accuracy\"])\n",
        "ax2.plot(history2.history[\"val_accuracy\"])\n",
        "ax2.set_title(\"validation accuracy\")\n",
        "ax2.set_xlabel(\"epochs\")\n",
        "ax2.set_ylim(0, 1)\n",
        "\n",
        "plt.show()\n",
        "plt.savefig('Test3_model_accuracy.png')"
      ],
      "metadata": {
        "id": "Tdytdh-Zm6Nh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}