{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Import necessary libraries"
      ],
      "metadata": {
        "id": "Ikscy8dpd0hC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_NFDeJ59dyk4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b348e0b-48c5-4c9f-f27a-6430eedc2a3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processor\t: 0\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 79\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "stepping\t: 0\n",
            "microcode\t: 0xffffffff\n",
            "cpu MHz\t\t: 2199.998\n",
            "cache size\t: 56320 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 2\n",
            "core id\t\t: 0\n",
            "cpu cores\t: 1\n",
            "apicid\t\t: 0\n",
            "initial apicid\t: 0\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 13\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa mmio_stale_data retbleed\n",
            "bogomips\t: 4399.99\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n",
            "processor\t: 1\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 79\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "stepping\t: 0\n",
            "microcode\t: 0xffffffff\n",
            "cpu MHz\t\t: 2199.998\n",
            "cache size\t: 56320 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 2\n",
            "core id\t\t: 0\n",
            "cpu cores\t: 1\n",
            "apicid\t\t: 1\n",
            "initial apicid\t: 1\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 13\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa mmio_stale_data retbleed\n",
            "bogomips\t: 4399.99\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n",
            "/bin/bash: line 1: nvidia-smi: command not found\n",
            "2.15.0\n"
          ]
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "\n",
        "!cat /proc/cpuinfo # gives details of CPU\n",
        "\n",
        "!nvidia-smi # gives details of GPU\n",
        "\n",
        "# !pip uninstall tensorflow  #just incase you want to change version\n",
        "# !pip install tensorflow==2.X.0\n",
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "\n",
        "# Commonly used modules\n",
        "import numpy as np\n",
        "import os, datetime\n",
        "import sys\n",
        "\n",
        "# Images, plots, display, and visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "import IPython\n",
        "from six.moves import urllib\n",
        "\n",
        "print(tf.__version__)\n",
        "\n",
        "\n",
        "from matplotlib.pyplot import imshow\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Load CIFAR100 dataset"
      ],
      "metadata": {
        "id": "O-Mg37THd90f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import cifar100\n",
        "(x_train, y_train), (x_test, y_test)  = cifar100.load_data()\n",
        "\n",
        "# return the modified images\n",
        "print(\"Train Images shape: \",x_train.shape)\n",
        "print(\"Test Images shape: \",x_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "-M1xncG-d9Xm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19c74a84-f296-4933-f43a-eed2261c649f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169001437/169001437 [==============================] - 4s 0us/step\n",
            "Train Images shape:  (50000, 32, 32, 3)\n",
            "Test Images shape:  (10000, 32, 32, 3)\n",
            "(50000, 1)\n",
            "(10000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Preprocess Image Data"
      ],
      "metadata": {
        "id": "Vn5_eVJFeFkN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_images(X, Y): # should work for both a single image and multiple images\n",
        "    X_p = keras.applications.densenet.preprocess_input(X)\n",
        "    Y_p = keras.utils.to_categorical(Y, 100)\n",
        "    return X_p, Y_p\n",
        "\n",
        "# preprocess the train images\n",
        "x_train, y_train = preprocess_images(x_train, y_train)\n",
        "\n",
        "# preprocess the test images\n",
        "x_test, y_test = preprocess_images(x_test, y_test)"
      ],
      "metadata": {
        "id": "LWpnnqINeI7J"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Baseline Model = VGG16\n",
        "Images need to be resized to make the best use of the base model"
      ],
      "metadata": {
        "id": "_lQcRi4seOR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "\n",
        "# input tensor\n",
        "inputs = keras.Input(shape=(32, 32, 3))\n",
        "\n",
        "# upscale layer\n",
        "upscale = keras.layers.Lambda(lambda x: tf.image.resize_with_pad(x,\n",
        "            160,\n",
        "            160,\n",
        "            method=tf.image.ResizeMethod.BILINEAR))(inputs)\n",
        "\n",
        "base_model = VGG16(weights='imagenet',\n",
        "                   include_top=False,\n",
        "                   input_tensor=upscale,\n",
        "                   input_shape=(160,160,3),\n",
        "                   pooling='max')\n",
        "\n",
        "base_model.summary()"
      ],
      "metadata": {
        "id": "VRK2XTuXemdG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fe276c4-9618-4635-bea4-801981897327"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " lambda_2 (Lambda)           (None, 160, 160, 3)       0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 160, 160, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 160, 160, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 80, 80, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 80, 80, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 80, 80, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 40, 40, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 40, 40, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 40, 40, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 40, 40, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 20, 20, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 20, 20, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 20, 20, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 20, 20, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 10, 10, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 10, 10, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 10, 10, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 10, 10, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 5, 5, 512)         0         \n",
            "                                                                 \n",
            " global_max_pooling2d_2 (Gl  (None, 512)               0         \n",
            " obalMaxPooling2D)                                               \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14714688 (56.13 MB)\n",
            "Trainable params: 14714688 (56.13 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## The head eg. fully connected network must be set up specific to this dataset\n",
        "out = base_model.output\n",
        "out = keras.layers.Flatten()(out)\n",
        "out = keras.layers.BatchNormalization()(out)\n",
        "out = keras.layers.Dense(256, activation='relu')(out)\n",
        "out = keras.layers.Dropout(0.3)(out)\n",
        "out = keras.layers.BatchNormalization()(out)\n",
        "out = keras.layers.Dense(128, activation='relu')(out)\n",
        "out = keras.layers.Dropout(0.3)(out)\n",
        "out = keras.layers.BatchNormalization()(out)\n",
        "out = keras.layers.Dense(64, activation='relu')(out)\n",
        "out = keras.layers.Dropout(0.3)(out)\n",
        "out = keras.layers.Dense(100, activation='softmax')(out) #key change is that there are 100 output nodes for the 100 classes"
      ],
      "metadata": {
        "id": "vOynT577gH1Q"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analysing Baseline Model"
      ],
      "metadata": {
        "id": "x15YdKCiggeH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CALLBACKS = []\n",
        "MODEL_PATH = 'cifar100.h5'\n",
        "\n",
        "# callbacks\n",
        "CALLBACKS.append(keras.callbacks.ModelCheckpoint(filepath=MODEL_PATH,\n",
        "                                              monitor='val_acc',\n",
        "                                              save_best_only=True))\n",
        "\n",
        "CALLBACKS.append(keras.callbacks.EarlyStopping(monitor='val_acc',\n",
        "                                            verbose=1,\n",
        "                                            patience=5))\n",
        "\n",
        "CALLBACKS.append(keras.callbacks.TensorBoard(log_dir='logs'))\n",
        "\n",
        "model = keras.models.Model(inputs=inputs, outputs=out)\n",
        "\n",
        "# compile the model to use categorical cross-entropy loss function and adadelta optimizer\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=keras.optimizers.Adam(learning_rate = 0.001),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x=x_train, y=y_train,\n",
        "                    batch_size=128,\n",
        "                    epochs=15,\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    callbacks=CALLBACKS)"
      ],
      "metadata": {
        "id": "TW4PCLCtglPm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(16,4))\n",
        "ax = fig.add_subplot(121)\n",
        "ax.plot(history.history[\"val_loss\"])\n",
        "ax.plot(history2.history[\"val_loss\"])\n",
        "ax.set_title(\"validation loss\")\n",
        "ax.set_xlabel(\"epochs\")\n",
        "\n",
        "ax2 = fig.add_subplot(122)\n",
        "ax2.plot(history.history[\"val_accuracy\"])\n",
        "ax2.plot(history2.history[\"val_accuracy\"])\n",
        "ax2.set_title(\"validation accuracy\")\n",
        "ax2.set_xlabel(\"epochs\")\n",
        "ax2.set_ylim(0, 1)\n",
        "\n",
        "plt.show()\n",
        "plt.savefig('Baseline_model_accuracy.png')"
      ],
      "metadata": {
        "id": "CfYXtTQ8g3yy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analysing Baseline Model with frozen backbone"
      ],
      "metadata": {
        "id": "5Vy8gwmYihss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "frozen_model = VGG16(weights='imagenet',\n",
        "                   include_top=False,\n",
        "                   input_tensor=upscale,\n",
        "                   input_shape=(160,160,3),\n",
        "                   pooling='max')\n",
        "# Might need to remove the pooling max to then compare against"
      ],
      "metadata": {
        "id": "pxcvpOXuhG8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frozen_model.trainable = False # freeze backbone"
      ],
      "metadata": {
        "id": "OQEM2yGaj8u9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=(160, 160, 3))\n",
        "# We make sure that the base_model is running in inference mode here,\n",
        "# by passing `training=False`\n",
        "x = frozen_model(inputs, training=False)\n",
        "# Convert features of shape `base_model.output_shape[1:]` to vectors\n",
        "# x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = frozen_model.output\n",
        "x = keras.layers.Flatten()(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.Dense(256, activation='relu')(x)\n",
        "x = keras.layers.Dropout(0.3)(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.Dense(128, activation='relu')(x)\n",
        "x = keras.layers.Dropout(0.3)(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.Dense(64, activation='relu')(x)\n",
        "x = keras.layers.Dropout(0.3)(x)\n",
        "# A Dense classifier with a 100 classes\n",
        "outputs = keras.layers.Dense(100, activation='softmax')(x)"
      ],
      "metadata": {
        "id": "3W4cp2LIj8yW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CALLBACKS = []\n",
        "MODEL_PATH = 'cifar100.h5'\n",
        "\n",
        "# callbacks\n",
        "CALLBACKS.append(keras.callbacks.ModelCheckpoint(filepath=MODEL_PATH,\n",
        "                                              monitor='val_acc',\n",
        "                                              save_best_only=True))\n",
        "\n",
        "CALLBACKS.append(keras.callbacks.EarlyStopping(monitor='val_acc',\n",
        "                                            verbose=1,\n",
        "                                            patience=5))\n",
        "\n",
        "CALLBACKS.append(keras.callbacks.TensorBoard(log_dir='logs'))\n",
        "\n",
        "model = keras.models.Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "b_N_cJmTnZwq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=keras.optimizers.Adam(learning_rate = 0.001),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x=x_train, y=y_train,\n",
        "                    batch_size=128,\n",
        "                    epochs=15,\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    callbacks=CALLBACKS)"
      ],
      "metadata": {
        "id": "viiXSPUMkwyp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(16,4))\n",
        "ax = fig.add_subplot(121)\n",
        "ax.plot(history.history[\"val_loss\"])\n",
        "ax.plot(history2.history[\"val_loss\"])\n",
        "ax.set_title(\"validation loss\")\n",
        "ax.set_xlabel(\"epochs\")\n",
        "\n",
        "ax2 = fig.add_subplot(122)\n",
        "ax2.plot(history.history[\"val_accuracy\"])\n",
        "ax2.plot(history2.history[\"val_accuracy\"])\n",
        "ax2.set_title(\"validation accuracy\")\n",
        "ax2.set_xlabel(\"epochs\")\n",
        "ax2.set_ylim(0, 1)\n",
        "\n",
        "plt.show()\n",
        "plt.savefig('Frozen_Baseline_model_accuracy.png')"
      ],
      "metadata": {
        "id": "4VzQyXYwoOHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Test Model 1 = DenseNet121\n",
        "Selected due to lower size and parameters than baseline model but higher top1 and top5 accuracy likely due to the depth of the Model."
      ],
      "metadata": {
        "id": "mJBjlBoKfJY6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_model1 = keras.applications.DenseNet121(include_top=False,\n",
        "                                        weights='imagenet',\n",
        "                                        input_tensor=upscale,\n",
        "                                        input_shape=(160,160,3),\n",
        "                                        pooling='max')\n",
        "\n",
        "test_model1.summary()"
      ],
      "metadata": {
        "id": "j_BtIpGMgBG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = test_model1.output\n",
        "out = keras.layers.Flatten()(out)\n",
        "out = keras.layers.BatchNormalization()(out)\n",
        "out = keras.layers.Dense(256, activation='relu')(out)\n",
        "out = keras.layers.Dropout(0.3)(out)\n",
        "out = keras.layers.BatchNormalization()(out)\n",
        "out = keras.layers.Dense(128, activation='relu')(out)\n",
        "out = keras.layers.Dropout(0.3)(out)\n",
        "out = keras.layers.BatchNormalization()(out)\n",
        "out = keras.layers.Dense(64, activation='relu')(out)\n",
        "out = keras.layers.Dropout(0.3)(out)\n",
        "out = keras.layers.Dense(100, activation='softmax')(out) #key change is that there are 100 output nodes for the 100 classes"
      ],
      "metadata": {
        "id": "cN_115pElidE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CALLBACKS = []\n",
        "MODEL_PATH = 'cifar100.h5'\n",
        "\n",
        "# callbacks\n",
        "CALLBACKS.append(keras.callbacks.ModelCheckpoint(filepath=MODEL_PATH,\n",
        "                                              monitor='val_acc',\n",
        "                                              save_best_only=True))\n",
        "\n",
        "CALLBACKS.append(keras.callbacks.EarlyStopping(monitor='val_acc',\n",
        "                                            verbose=1,\n",
        "                                            patience=5))\n",
        "\n",
        "CALLBACKS.append(keras.callbacks.TensorBoard(log_dir='logs'))\n",
        "\n",
        "model = keras.models.Model(inputs, outputs)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=keras.optimizers.Adam(learning_rate = 0.001),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x=x_train, y=y_train,\n",
        "                    batch_size=128,\n",
        "                    epochs=15,\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    callbacks=CALLBACKS)"
      ],
      "metadata": {
        "id": "oOMJKZFdmf-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(16,4))\n",
        "ax = fig.add_subplot(121)\n",
        "ax.plot(history.history[\"val_loss\"])\n",
        "ax.plot(history2.history[\"val_loss\"])\n",
        "ax.set_title(\"validation loss\")\n",
        "ax.set_xlabel(\"epochs\")\n",
        "\n",
        "ax2 = fig.add_subplot(122)\n",
        "ax2.plot(history.history[\"val_accuracy\"])\n",
        "ax2.plot(history2.history[\"val_accuracy\"])\n",
        "ax2.set_title(\"validation accuracy\")\n",
        "ax2.set_xlabel(\"epochs\")\n",
        "ax2.set_ylim(0, 1)\n",
        "\n",
        "plt.show()\n",
        "plt.savefig('Test1_model_accuracy.png')"
      ],
      "metadata": {
        "id": "q--Vj_w8mnZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Test Model 2 = Xception"
      ],
      "metadata": {
        "id": "qPbr2339hvx-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_model2 = keras.applications.Xception(include_top=False,\n",
        "                                          weights='imagenet',\n",
        "                                          input_tensor=upscale,\n",
        "                                          input_shape=(160,160,3),\n",
        "                                          pooling='max')\n",
        "\n",
        "test_model2.summary()"
      ],
      "metadata": {
        "id": "Gs8SalVkh743"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = test_model2.output\n",
        "out = keras.layers.Flatten()(out)\n",
        "out = keras.layers.BatchNormalization()(out)\n",
        "out = keras.layers.Dense(256, activation='relu')(out)\n",
        "out = keras.layers.Dropout(0.3)(out)\n",
        "out = keras.layers.BatchNormalization()(out)\n",
        "out = keras.layers.Dense(128, activation='relu')(out)\n",
        "out = keras.layers.Dropout(0.3)(out)\n",
        "out = keras.layers.BatchNormalization()(out)\n",
        "out = keras.layers.Dense(64, activation='relu')(out)\n",
        "out = keras.layers.Dropout(0.3)(out)\n",
        "out = keras.layers.Dense(100, activation='softmax')(out) #key change is that there are 100 output nodes for the 100 classes"
      ],
      "metadata": {
        "id": "_Kibr2f-lkjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CALLBACKS = []\n",
        "MODEL_PATH = 'cifar100.h5'\n",
        "\n",
        "# callbacks\n",
        "CALLBACKS.append(keras.callbacks.ModelCheckpoint(filepath=MODEL_PATH,\n",
        "                                              monitor='val_acc',\n",
        "                                              save_best_only=True))\n",
        "\n",
        "CALLBACKS.append(keras.callbacks.EarlyStopping(monitor='val_acc',\n",
        "                                            verbose=1,\n",
        "                                            patience=5))\n",
        "\n",
        "CALLBACKS.append(keras.callbacks.TensorBoard(log_dir='logs'))\n",
        "\n",
        "model = keras.models.Model(inputs, outputs)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=keras.optimizers.Adam(learning_rate = 0.001),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x=x_train, y=y_train,\n",
        "                    batch_size=128,\n",
        "                    epochs=15,\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    callbacks=CALLBACKS)"
      ],
      "metadata": {
        "id": "CQ3zoIEimuSz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(16,4))\n",
        "ax = fig.add_subplot(121)\n",
        "ax.plot(history.history[\"val_loss\"])\n",
        "ax.plot(history2.history[\"val_loss\"])\n",
        "ax.set_title(\"validation loss\")\n",
        "ax.set_xlabel(\"epochs\")\n",
        "\n",
        "ax2 = fig.add_subplot(122)\n",
        "ax2.plot(history.history[\"val_accuracy\"])\n",
        "ax2.plot(history2.history[\"val_accuracy\"])\n",
        "ax2.set_title(\"validation accuracy\")\n",
        "ax2.set_xlabel(\"epochs\")\n",
        "ax2.set_ylim(0, 1)\n",
        "\n",
        "plt.show()\n",
        "plt.savefig('Test2_model_accuracy.png')"
      ],
      "metadata": {
        "id": "dt83gLk1mvJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Model 3 = ResNet101"
      ],
      "metadata": {
        "id": "7a-uwLWvh1wC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_model3 = keras.applications.ResNet101(include_top=False,\n",
        "                                          weights='imagenet',\n",
        "                                          input_tensor=upscale,\n",
        "                                          input_shape=(160,160,3),\n",
        "                                          pooling='max')\n",
        "\n",
        "test_model3.summary()"
      ],
      "metadata": {
        "id": "BZVhB7fBiNDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = test_model3.output\n",
        "out = keras.layers.Flatten()(out)\n",
        "out = keras.layers.BatchNormalization()(out)\n",
        "out = keras.layers.Dense(256, activation='relu')(out)\n",
        "out = keras.layers.Dropout(0.3)(out)\n",
        "out = keras.layers.BatchNormalization()(out)\n",
        "out = keras.layers.Dense(128, activation='relu')(out)\n",
        "out = keras.layers.Dropout(0.3)(out)\n",
        "out = keras.layers.BatchNormalization()(out)\n",
        "out = keras.layers.Dense(64, activation='relu')(out)\n",
        "out = keras.layers.Dropout(0.3)(out)\n",
        "out = keras.layers.Dense(100, activation='softmax')(out) #key change is that there are 100 output nodes for the 100 classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "M3A2CvY1llh9",
        "outputId": "a3842ede-a1cc-46d5-b6f8-99b858ba5b49"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'base_model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-6e6f8892853e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'base_model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CALLBACKS = []\n",
        "MODEL_PATH = 'cifar100.h5'\n",
        "\n",
        "# callbacks\n",
        "CALLBACKS.append(keras.callbacks.ModelCheckpoint(filepath=MODEL_PATH,\n",
        "                                              monitor='val_acc',\n",
        "                                              save_best_only=True))\n",
        "\n",
        "CALLBACKS.append(keras.callbacks.EarlyStopping(monitor='val_acc',\n",
        "                                            verbose=1,\n",
        "                                            patience=5))\n",
        "\n",
        "CALLBACKS.append(keras.callbacks.TensorBoard(log_dir='logs'))\n",
        "\n",
        "model = keras.models.Model(inputs, outputs)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=keras.optimizers.Adam(learning_rate = 0.001),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x=x_train, y=y_train,\n",
        "                    batch_size=128,\n",
        "                    epochs=15,\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    callbacks=CALLBACKS)"
      ],
      "metadata": {
        "id": "GPuY5-Fymy1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(16,4))\n",
        "ax = fig.add_subplot(121)\n",
        "ax.plot(history.history[\"val_loss\"])\n",
        "ax.plot(history2.history[\"val_loss\"])\n",
        "ax.set_title(\"validation loss\")\n",
        "ax.set_xlabel(\"epochs\")\n",
        "\n",
        "ax2 = fig.add_subplot(122)\n",
        "ax2.plot(history.history[\"val_accuracy\"])\n",
        "ax2.plot(history2.history[\"val_accuracy\"])\n",
        "ax2.set_title(\"validation accuracy\")\n",
        "ax2.set_xlabel(\"epochs\")\n",
        "ax2.set_ylim(0, 1)\n",
        "\n",
        "plt.show()\n",
        "plt.savefig('Test3_model_accuracy.png')"
      ],
      "metadata": {
        "id": "gHFHevotm1VR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Test Model 4 = ResNet152"
      ],
      "metadata": {
        "id": "QFPE58j-h5Xf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_model4 = keras.applications.ResNet152(include_top=False,\n",
        "                                          weights='imagenet',\n",
        "                                          input_tensor=upscale,\n",
        "                                          input_shape=(160,160,3),\n",
        "                                          pooling='max')\n",
        "\n",
        "test_model4.summary()"
      ],
      "metadata": {
        "id": "YjRKHioooVIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = test_model4.output\n",
        "out = keras.layers.Flatten()(out)\n",
        "out = keras.layers.BatchNormalization()(out)\n",
        "out = keras.layers.Dense(256, activation='relu')(out)\n",
        "out = keras.layers.Dropout(0.3)(out)\n",
        "out = keras.layers.BatchNormalization()(out)\n",
        "out = keras.layers.Dense(128, activation='relu')(out)\n",
        "out = keras.layers.Dropout(0.3)(out)\n",
        "out = keras.layers.BatchNormalization()(out)\n",
        "out = keras.layers.Dense(64, activation='relu')(out)\n",
        "out = keras.layers.Dropout(0.3)(out)\n",
        "out = keras.layers.Dense(100, activation='softmax')(out) #key change is that there are 100 output nodes for the 100 classes"
      ],
      "metadata": {
        "id": "5oqS85sElona"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CALLBACKS = []\n",
        "MODEL_PATH = 'cifar100.h5'\n",
        "\n",
        "# callbacks\n",
        "CALLBACKS.append(keras.callbacks.ModelCheckpoint(filepath=MODEL_PATH,\n",
        "                                              monitor='val_acc',\n",
        "                                              save_best_only=True))\n",
        "\n",
        "CALLBACKS.append(keras.callbacks.EarlyStopping(monitor='val_acc',\n",
        "                                            verbose=1,\n",
        "                                            patience=5))\n",
        "\n",
        "CALLBACKS.append(keras.callbacks.TensorBoard(log_dir='logs'))\n",
        "\n",
        "model = keras.models.Model(inputs, outputs)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=keras.optimizers.Adam(learning_rate = 0.001),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x=x_train, y=y_train,\n",
        "                    batch_size=128,\n",
        "                    epochs=15,\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    callbacks=CALLBACKS)"
      ],
      "metadata": {
        "id": "VWu7kPnNm5tA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(16,4))\n",
        "ax = fig.add_subplot(121)\n",
        "ax.plot(history.history[\"val_loss\"])\n",
        "ax.plot(history2.history[\"val_loss\"])\n",
        "ax.set_title(\"validation loss\")\n",
        "ax.set_xlabel(\"epochs\")\n",
        "\n",
        "ax2 = fig.add_subplot(122)\n",
        "ax2.plot(history.history[\"val_accuracy\"])\n",
        "ax2.plot(history2.history[\"val_accuracy\"])\n",
        "ax2.set_title(\"validation accuracy\")\n",
        "ax2.set_xlabel(\"epochs\")\n",
        "ax2.set_ylim(0, 1)\n",
        "\n",
        "plt.show()\n",
        "plt.savefig('Test3_model_accuracy.png')"
      ],
      "metadata": {
        "id": "Tdytdh-Zm6Nh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}